# /services/my_model.py
"""
Security Operations LLM Agent Interface

Core functionality:
- Initialize LLM agent with document search and security tools
- Pass user messages to agent for intelligent processing
- Agent decides what tools to use and how to respond
- Persistent conversation storage with SQLite database
- Enhanced error recovery with graceful fallbacks
- Session management across bot restarts

Features:
- SQLite-based conversation persistence (30 messages per session)
- Intelligent retry logic with exponential backoff
- Context-aware fallback responses when tools fail
- Automatic session cleanup and health monitoring
- 4K character context window with token limits

Created for MetLife Security Operations
"""
import logging
import time
from pokedex_bot.core.state_manager import get_state_manager
from pokedex_bot.core.session_manager import get_session_manager
from pokedex_bot.core.error_recovery import get_recovery_manager, enhanced_agent_wrapper

logging.basicConfig(level=logging.INFO)


def run_health_tests_command() -> str:
    """Execute health tests and return formatted results"""
    try:
        from pokedex_bot.tests.system_health_tests import run_health_tests
        
        # Run the health tests
        logging.info("ğŸ”¬ Running health tests via chat command...")
        test_results = run_health_tests()
        
        # Format results for chat response
        total_tests = len(test_results)
        passed_tests = sum(1 for result in test_results.values() if result.get('status') == 'PASS')
        failed_tests = total_tests - passed_tests
        
        # Create summary
        if failed_tests == 0:
            status_emoji = "âœ…"
            status_text = "ALL TESTS PASSED"
        elif failed_tests <= 2:
            status_emoji = "âš ï¸"
            status_text = "SOME TESTS FAILED"
        else:
            status_emoji = "âŒ"
            status_text = "MULTIPLE TESTS FAILED"
        
        response = f"ğŸ”¬ **Health Test Report**\\n\\n"
        response += f"{status_emoji} **Status**: {status_text}\\n"
        response += f"ğŸ“Š **Summary**: {passed_tests}/{total_tests} tests passed\\n\\n"
        
        # Add individual test results
        for test_name, result in test_results.items():
            status = result.get('status', 'UNKNOWN')
            duration = result.get('duration', 'N/A')
            emoji = "âœ…" if status == 'PASS' else "âŒ"
            
            response += f"{emoji} **{test_name}**: {status} ({duration})\\n"
            
            # Add error details for failed tests
            if status in ['FAIL', 'ERROR'] and result.get('error'):
                response += f"â””â”€ Error: {result['error']}\\n"
        
        return response
        
    except Exception as e:
        logging.error(f"Failed to run health tests: {e}")
        return f"âŒ **Health Test Error**\\n\\nFailed to execute health tests: {str(e)}\\n\\nğŸ’¡ **Manual run**: `python pokedx_bot/tests/system_health_tests.py`"


def initialize_model_and_agent():
    """
    Initialize the LLM, embeddings, and agent with enhanced capabilities.
    
    Initializes:
    - State manager for LLM and agent components
    - Session manager for persistent conversation storage
    - Error recovery manager for graceful failure handling
    
    Returns:
        bool: True if initialization successful, False otherwise
    """
    state_manager = get_state_manager()
    success = state_manager.initialize_all_components()

    if success:
        logging.info("SecurityBot initialized successfully")
    else:
        logging.error("SecurityBot initialization failed")

    return success


def ask(user_message: str, user_id: str = "default", room_id: str = "default") -> str:
    """
    SOC Q&A function with persistent sessions and enhanced error recovery:
    
    1. Retrieves conversation context from persistent SQLite storage
    2. Passes message to LLM agent with enhanced error handling
    3. Agent decides what tools/documents are needed with retry logic
    4. Gracefully handles tool failures with context-aware fallbacks
    5. Stores conversation in persistent session for future context
    6. Returns complete response with proper attribution
    
    Features:
    - Persistent conversation context across bot restarts
    - Enhanced error recovery with intelligent fallbacks
    - Automatic session cleanup and health monitoring
    - Fast responses for simple queries (health, greetings)
    
    Args:
        user_message: The user's question or request
        user_id: Unique identifier for the user (default: "default")
        room_id: Unique identifier for the chat room (default: "default")
        
    Returns:
        str: Complete response from the SOC assistant
    """

    start_time = time.time()

    try:
        # Basic validation
        if not user_message or not user_message.strip():
            return "Please ask me a question!"

        query = user_message.strip()

        # Remove bot name prefixes if present (common in group chats)
        bot_names = ['DnR_Pokedex', 'Pokedex', 'pokedex', 'dnr_pokedex']
        for bot_name in bot_names:
            if query.lower().startswith(bot_name.lower()):
                query = query[len(bot_name):].strip()
                break

        # Create unique session key for user + room combination
        session_key = f"{user_id}_{room_id}"

        # Get session manager for context
        state_manager = get_state_manager()
        if state_manager and not state_manager.is_initialized:
            logging.error("State manager not initialized. Bot must be initialized before use.")
            return "âŒ Bot not ready. Please try again in a moment."

        # Get session manager for persistent sessions
        session_manager = get_session_manager()
        
        # Clean up old sessions periodically
        session_manager.cleanup_old_sessions()

        # Get conversation context from session history
        conversation_context = session_manager.get_conversation_context(session_key)

        # Quick responses for simple queries (performance optimization)
        simple_query = query.lower().strip()
        if simple_query in ['status', 'health', 'are you working', 'hello', 'hi', 'run health tests', 'health tests', 'run tests']:
            if simple_query in ['status', 'health', 'are you working']:
                final_response = "âœ… System online and ready"
            elif simple_query in ['run health tests', 'health tests', 'run tests']:
                final_response = run_health_tests_command()
            else:  # greetings
                final_response = """ğŸ‘‹ Hello! I'm your SOC Q&A Assistant

I'm here to help with security operations by searching our local SOC documentation and using available security tools.

ğŸ”’ Security Note: I operate in a secure environment with:
â€¢ Access to internal SOC documents and procedures
â€¢ Integration with security tools (CrowdStrike, Tanium, etc.)
â€¢ No internet access - all responses from local resources only

â“ How I can help:
â€¢ Answer questions about security procedures
â€¢ Search SOC documentation and runbooks
â€¢ Check device status and containment
â€¢ Provide step-by-step incident response guidance

Just ask me any security-related question!"""
            
            # Store simple interaction in session
            session_manager.add_message(session_key, "user", query)
            session_manager.add_message(session_key, "assistant", final_response)
            
            elapsed = time.time() - start_time
            if elapsed > 25:
                logging.warning(f"Response took {elapsed:.1f}s")
            return final_response

        # STEP 1: For complex queries, pass to LLM agent - let it decide everything
        try:
            agent_executor = state_manager.get_agent_executor() if state_manager else None
            logging.info(f"Agent executor available: {agent_executor is not None}")

            if agent_executor:
                # Prepare input with conversation context
                agent_input = query
                if conversation_context:
                    agent_input = conversation_context + " " + query
                    logging.debug(f"Added conversation context to query")

                # Let the LLM agent handle everything with enhanced error recovery
                logging.info(f"Passing query to LLM agent: {query[:100]}...")
                recovery_manager = get_recovery_manager()
                
                try:
                    final_response = enhanced_agent_wrapper(agent_executor, agent_input, recovery_manager)
                    # Store user message and bot response in session
                    session_manager.add_message(session_key, "user", query)
                    session_manager.add_message(session_key, "assistant", final_response)
                except Exception as e:
                    logging.error(f"Enhanced agent wrapper failed: {e}")
                    final_response = recovery_manager.get_fallback_response('general', query)
                    # Still store the interaction for context
                    session_manager.add_message(session_key, "user", query)
                    session_manager.add_message(session_key, "assistant", final_response)
            else:
                logging.error("Agent executor not available - system not properly initialized")
                final_response = "âŒ System not ready. Please try again in a moment."

        except Exception as e:
            logging.error(f"Failed to invoke agent: {e}")
            final_response = "âŒ An error occurred. Please try again or contact support."

        elapsed = time.time() - start_time
        if elapsed > 25:
            logging.warning(f"Response took {elapsed:.1f}s")

        return final_response

    except Exception as e:
        logging.error(f"Ask function failed: {e}")
        return "âŒ An error occurred. Please try again or contact support."
